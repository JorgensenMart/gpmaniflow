{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb1e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8dfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uci_datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6d68ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buzz dataset, N=583250, d=77\n"
     ]
    }
   ],
   "source": [
    "data_name = \"buzz\"\n",
    "data = Dataset(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b388773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  42.66   90.23  122.32 ...  130.4   118.29  110.06]\n",
      " [1178.7  1134.2   597.32 ... 1137.4  1151.3  1050.1 ]\n",
      " [-135.34 -133.77 -159.68 ... -199.6  -209.71 -197.94]\n",
      " ...\n",
      " [ 533.66  709.23  714.32 ...  809.4   737.29  860.06]\n",
      " [-139.34 -136.77 -159.68 ... -199.6  -220.71 -218.94]\n",
      " [-138.34 -132.77 -158.68 ... -195.6  -220.71 -216.94]]\n",
      "[[ 2.163  ]\n",
      " [ 3.6614 ]\n",
      " [-0.45896]\n",
      " ...\n",
      " [ 3.6842 ]\n",
      " [-2.7103 ]\n",
      " [-1.052  ]]\n",
      "[     0      1      2 ... 583247 583248 583249]\n",
      "388833\n"
     ]
    }
   ],
   "source": [
    "X = data.x\n",
    "Y = data.y\n",
    "#X = data[:,:-1]\n",
    "#Y = data[:, -1].reshape(-1,1)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "ind = np.arange(X.shape[0])\n",
    "print(ind)\n",
    "prop = 0.9\n",
    "if data_name == \"buzz\":\n",
    "    prop = 6/9\n",
    "n = int(X.shape[0] * prop)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa2f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 11:53:29.244901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-15 11:53:29.244960: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from gpmaniflow.models.BezierProcess2 import BezierProcess\n",
    "from gpflow.likelihoods import Gaussian\n",
    "from gpflow.models import SGPR\n",
    "from gpflow.inducing_variables import InducingPoints\n",
    "import gpflow\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from gpflow.utilities import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8431a07c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 of 20\n",
      "1.5930762603557576\n",
      "0.01\n",
      "(194417, 77)\n",
      "(194409, 77)\n",
      "0.9955368514185922\n",
      "0.01\n",
      "(194409, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 11:53:47.629913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-15 11:53:47.631611: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-15 11:53:47.632307: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (martinj): /proc/driver/nvidia/version does not exist\n",
      "2022-05-15 11:53:47.643076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-15 11:53:47.967024: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-05-15 11:53:47.970859: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 239521128 exceeds 10% of free system memory.\n",
      "2022-05-15 11:53:48.177120: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 239521128 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 11:54:04.172164: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-15 11:54:24.375496: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 220095 of 388833\n",
      "2022-05-15 11:54:34.321140: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 239110 of 388833\n",
      "2022-05-15 11:54:44.310664: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 242779 of 388833\n",
      "2022-05-15 11:54:54.340200: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 242838 of 388833\n",
      "2022-05-15 11:55:04.309911: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 260533 of 388833\n",
      "2022-05-15 11:55:14.385152: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 269999 of 388833\n",
      "2022-05-15 11:55:24.346681: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 270040 of 388833\n",
      "2022-05-15 11:55:34.323501: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 272320 of 388833\n",
      "2022-05-15 11:55:44.663376: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274013 of 388833\n",
      "2022-05-15 11:55:54.481469: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274029 of 388833\n",
      "2022-05-15 11:56:04.736828: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274046 of 388833\n",
      "2022-05-15 11:56:14.811803: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274071 of 388833\n",
      "2022-05-15 11:56:24.209197: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274087 of 388833\n",
      "2022-05-15 11:56:34.504716: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274211 of 388833\n",
      "2022-05-15 11:56:44.362951: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274228 of 388833\n",
      "2022-05-15 11:56:54.435063: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274251 of 388833\n",
      "2022-05-15 11:57:04.514085: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274280 of 388833\n",
      "2022-05-15 11:57:14.771369: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 274613 of 388833\n",
      "2022-05-15 11:57:24.283173: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 276119 of 388833\n",
      "2022-05-15 11:57:34.476879: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 276155 of 388833\n",
      "2022-05-15 11:57:44.839769: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 276184 of 388833\n",
      "2022-05-15 11:57:54.257625: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 276661 of 388833\n",
      "2022-05-15 11:58:04.332696: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 278380 of 388833\n",
      "2022-05-15 11:58:14.431383: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 280591 of 388833\n",
      "2022-05-15 11:58:24.572001: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 282137 of 388833\n",
      "2022-05-15 11:58:34.251777: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 282337 of 388833\n",
      "2022-05-15 11:58:44.380936: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 285094 of 388833\n",
      "2022-05-15 11:58:54.321571: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 291543 of 388833\n",
      "2022-05-15 11:59:04.257100: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 291727 of 388833\n",
      "2022-05-15 11:59:14.648324: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 292172 of 388833\n",
      "2022-05-15 11:59:24.225619: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 292218 of 388833\n",
      "2022-05-15 11:59:34.550141: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 293257 of 388833\n",
      "2022-05-15 11:59:44.410240: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 294403 of 388833\n",
      "2022-05-15 11:59:54.458714: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 294491 of 388833\n",
      "2022-05-15 12:00:04.241627: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 295857 of 388833\n",
      "2022-05-15 12:00:14.766509: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 296067 of 388833\n",
      "2022-05-15 12:00:24.643871: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 296075 of 388833\n",
      "2022-05-15 12:00:27.900788: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n",
      "2022-05-15 12:00:28.132756: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 129360000 exceeds 10% of free system memory.\n",
      "2022-05-15 12:00:29.554048: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 129360000 exceeds 10% of free system memory.\n",
      "2022-05-15 12:00:50.142314: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 129360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_238411/3935215192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimization_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0melbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mbatchrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmeany\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstdy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/gpflow/models/training_mixins.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpmaniflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BezierRMSE = np.zeros(3)\n",
    "BezierRMedSE = np.zeros(3)\n",
    "BezierTestLL = np.zeros(3)\n",
    "\n",
    "\n",
    "ITERATIONS = 10000\n",
    "ORDER = 20\n",
    "BATCH_SIZE = 500\n",
    "INPUT_DIM = X.shape[1]\n",
    "\n",
    "for i in range(3):\n",
    "    print('Split', i + 1, 'of', 20)\n",
    "    np.random.seed(666 + i) # The devil's seed\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    ### GET TRAINING SPLIT AND PREPROCESS ###\n",
    "    \n",
    "    Xtrain = X[ind[:n], :]; Ytrain = Y[ind[:n], :]\n",
    "    Xtest = X[ind[n:], :]; Ytest = Y[ind[n:], :]\n",
    "    \n",
    "    mi, ma = Xtrain.min(axis=0), Xtrain.max(axis=0)\n",
    "    mami = ma - mi\n",
    "    mami = np.where(mami > 1e-6, mami, 1.) # Don't divide by zero\n",
    "    Xtrain = (Xtrain - mi) / mami\n",
    "    Xtest = (Xtest - mi) / mami\n",
    "\n",
    "    mi = 0.01\n",
    "    ma = 0.99\n",
    "    mami2 = np.where(mami > 1e-6, mami, 0.)\n",
    "    Xtrain = Xtrain * (ma - mi) + mi\n",
    "    Xtest = Xtest * (ma - mi) + mi\n",
    "    print(Xtest.max())\n",
    "    print(Xtest.min())\n",
    "    print(Xtest.shape)\n",
    "    Xtest21 = Xtest[Xtest.min(axis=1)>-0.01,:]\n",
    "    Xtest2 = Xtest21[Xtest21.max(axis=1)<1.01,:]\n",
    "    print(Xtest2.shape)\n",
    "    print(Xtest2.max())\n",
    "    print(Xtest2.min())\n",
    "    meany, stdy = np.average(Ytrain), np.std(Ytrain)\n",
    "    Ytrain = (Ytrain - meany) / stdy\n",
    "    Ytest2 = Ytest[Xtest.min(axis=1)>-0.01,:]\n",
    "    Ytest2 = Ytest2[Xtest21.max(axis=1)<1.01,:]\n",
    "    print(Ytest2.shape)\n",
    "    ############## BEZIER GP ##################\n",
    "    \n",
    "    m = BezierProcess(input_dim = INPUT_DIM, orders = ORDER, likelihood = Gaussian(), num_data = Xtrain.shape[0])\n",
    "    m.likelihood.variance.assign(1.0)\n",
    "    gpflow.set_trainable(m.likelihood.variance, False)\n",
    "    \n",
    "    minibatch_size = BATCH_SIZE\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((Xtrain, Ytrain)).repeat().shuffle(Xtrain.shape[0])\n",
    "    train_iter = iter(train_dataset.batch(minibatch_size))\n",
    "    \n",
    "    training_loss = m.training_loss_closure(train_iter, compile=True)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "    @tf.function\n",
    "    def optimization_step():\n",
    "        optimizer.minimize(training_loss, m.trainable_variables)\n",
    "\n",
    "    iterations = ITERATIONS\n",
    "    print('Training....')\n",
    "    for step in range(iterations):\n",
    "        optimization_step()\n",
    "        if step % 500 == 0:\n",
    "            elbo = -training_loss().numpy()\n",
    "            pr, _ = m.predict_f(Xtest[:100,:])\n",
    "            batchrmse = np.sqrt(np.mean((Ytest[:100,:] - (meany + stdy*pr.numpy()))**2))\n",
    "            print('Split:', i + 1, 'Step:', step, 'Elbo:', elbo)\n",
    "            print('RMSE:', batchrmse)\n",
    "    \n",
    "    gpflow.set_trainable(m.BN, False) # FIX VARIATIONAL PARAMS\n",
    "    gpflow.set_trainable(m.likelihood.variance, True) # AND TRAIN ONLY LIKELIHOOD VARIANCE\n",
    "    \n",
    "    training_loss = m.training_loss_closure(train_iter, compile=True)\n",
    "    optimizer = tf.optimizers.Adam(learning_rate = 0.01)\n",
    "\n",
    "    @tf.function\n",
    "    def optimization_step():\n",
    "        optimizer.minimize(training_loss, m.trainable_variables)\n",
    "    for step in range(iterations):\n",
    "        optimization_step()\n",
    "        if step % 500 == 0:\n",
    "            elbo = -training_loss().numpy()\n",
    "            pr, _ = m.predict_f(Xtest[:100,:])\n",
    "            batchrmse = np.sqrt(np.mean((Ytest[:100,:] - (meany + stdy*pr.numpy()))**2))\n",
    "            print('Split:', i + 1, 'Step:', step, 'Elbo:', elbo)\n",
    "            print('RMSE:', batchrmse)\n",
    "    \n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((Xtest2, Ytest2))\n",
    "    test_iter = iter(test_dataset.batch(minibatch_size))\n",
    "    print('Testing...')\n",
    "    SE = 0.\n",
    "    loglik = 0.\n",
    "    for batch in test_iter:\n",
    "        xb = batch[0]\n",
    "        yb = batch[1]\n",
    "        preds, predvar = m.predict_f(xb)\n",
    "        SE += np.sum((yb - (meany + stdy*preds.numpy()))**2)\n",
    "        \n",
    "        pred_mean, pred_var = m.predict_y(xb)\n",
    "        pred_dist = tfp.distributions.Normal(loc=meany + pred_mean*stdy, scale=stdy*pred_var**0.5)\n",
    "        loglik += tf.reduce_sum(pred_dist.log_prob(yb)).numpy()\n",
    "        \n",
    "    RMSE = np.sqrt( SE / Xtest.shape[0] )\n",
    "    loglik = loglik / Xtest.shape[0]\n",
    "    print('RMSE:', RMSE)\n",
    "    print('Test log-likelihood:', loglik)\n",
    "    ### Append results\n",
    "    BezierRMSE[i] = RMSE\n",
    "    BezierRMedSE[i] = 0\n",
    "    BezierTestLL[i] = loglik\n",
    "    \n",
    "print('Experiment concluded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ad2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Iterations:', ITERATIONS)\n",
    "print('Order:', ORDER)\n",
    "print('Batch size:', BATCH_SIZE)\n",
    "print('Average RMSE:', np.mean(BezierRMSE), 'Standard deviation:', np.std(BezierRMSE))\n",
    "print('Average RMedSE:', np.mean(BezierRMedSE), 'Standard deviation:', np.std(BezierRMedSE))\n",
    "print('Average test-ll:', np.mean(BezierTestLL), 'Standard deviation:', np.std(BezierTestLL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
